{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d23b488",
   "metadata": {},
   "source": [
    "# Hidden Markov Model with Token and Numerical Sequences\n",
    "\n",
    "This notebook demonstrates how to train a Hidden Markov Model (HMM) that takes both token sequences and numerical data sequences as input and produces output token sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ddea8",
   "metadata": {},
   "source": [
    "Here's a breakdown of what the notebook covers:\n",
    "\n",
    "1. Data Preparation\n",
    "Creation of sample token sequences (e.g., ['A', 'B', 'C', 'D'])\n",
    "Generation of corresponding numerical data sequences (e.g., [0.5, 1.2, 0.8, 1.5])\n",
    "Definition of target output token sequences (e.g., ['X', 'Y', 'X', 'Z'])\n",
    "2. Feature Engineering\n",
    "Encoding categorical token data\n",
    "Combining token encodings with numerical data into a single feature matrix\n",
    "Preparing the data structure expected by HMM algorithms\n",
    "3. Model Training\n",
    "Training a Gaussian Hidden Markov Model using the combined features\n",
    "The model learns the relationship between input features and hidden states (output tokens)\n",
    "4. Evaluation\n",
    "Testing the model on new sequences\n",
    "Comparing predictions to ground truth\n",
    "Calculating accuracy metrics\n",
    "5. Visualization\n",
    "Visualizing transition probabilities between states\n",
    "Examining emission distributions for each state\n",
    "6. Making Predictions\n",
    "Applying the trained model to new, unseen data\n",
    "Converting predicted hidden states back to output tokens\n",
    "7. Advanced Techniques\n",
    "Discussion of alternative approaches for more complex scenarios\n",
    "The notebook is designed to be interactive and educational. You can run each cell to see how the model performs, and the code includes detailed comments explaining each step of the process.\n",
    "\n",
    "You'll need the following Python packages to run the notebook:\n",
    "\n",
    "numpy\n",
    "matplotlib\n",
    "hmmlearn\n",
    "scikit-learn\n",
    "(optionally) pomegranate for the custom HMM implementation section\n",
    "To try it out, open the notebook in your Jupyter environment and run the cells in sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d555268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6dd754",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hmmlearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhmmlearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hmm\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'hmmlearn'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf0c0a",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "We'll create sample data with:\n",
    "- Input token sequences (e.g., ['A', 'B', 'C', 'D'])\n",
    "- Corresponding numerical data (e.g., [0.5, 1.2, 0.8, 1.5])\n",
    "- Target output token sequences (e.g., ['X', 'Y', 'X', 'Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47677540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data generation\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate 100 sequences of length 4\n",
    "n_sequences = 100\n",
    "sequence_length = 4\n",
    "\n",
    "# Define possible input tokens and output tokens\n",
    "input_tokens = ['A', 'B', 'C', 'D']\n",
    "output_tokens = ['X', 'Y', 'Z']\n",
    "\n",
    "# Generate random input token sequences\n",
    "input_token_sequences = []\n",
    "for _ in range(n_sequences):\n",
    "    sequence = np.random.choice(input_tokens, size=sequence_length)\n",
    "    input_token_sequences.append(sequence)\n",
    "\n",
    "# Generate corresponding numerical data (with some patterns)\n",
    "numerical_data_sequences = []\n",
    "for seq in input_token_sequences:\n",
    "    numerical_seq = []\n",
    "    for token in seq:\n",
    "        if token == 'A':\n",
    "            numerical_seq.append(np.random.normal(0.5, 0.1))  # Mean 0.5, std 0.1\n",
    "        elif token == 'B':\n",
    "            numerical_seq.append(np.random.normal(1.2, 0.15))  # Mean 1.2, std 0.15\n",
    "        elif token == 'C':\n",
    "            numerical_seq.append(np.random.normal(0.8, 0.12))  # Mean 0.8, std 0.12\n",
    "        else:  # 'D'\n",
    "            numerical_seq.append(np.random.normal(1.5, 0.2))  # Mean 1.5, std 0.2\n",
    "    numerical_data_sequences.append(np.array(numerical_seq))\n",
    "\n",
    "# Generate output token sequences based on patterns in the input\n",
    "output_token_sequences = []\n",
    "for i in range(n_sequences):\n",
    "    output_seq = []\n",
    "    for j in range(sequence_length):\n",
    "        input_token = input_token_sequences[i][j]\n",
    "        num_val = numerical_data_sequences[i][j]\n",
    "        \n",
    "        # Logic to determine output token based on input token and numerical value\n",
    "        if input_token == 'A' and num_val < 0.5:\n",
    "            output_seq.append('X')\n",
    "        elif input_token == 'A' and num_val >= 0.5:\n",
    "            output_seq.append('Y')\n",
    "        elif input_token == 'B' and num_val < 1.2:\n",
    "            output_seq.append('X')\n",
    "        elif input_token == 'B' and num_val >= 1.2:\n",
    "            output_seq.append('Z')\n",
    "        elif input_token == 'C':\n",
    "            output_seq.append('Y')\n",
    "        else:  # 'D'\n",
    "            output_seq.append('Z')\n",
    "    \n",
    "    output_token_sequences.append(np.array(output_seq))\n",
    "\n",
    "# Display some examples\n",
    "print(\"Sample data:\")\n",
    "for i in range(5):  # Show first 5 sequences\n",
    "    print(f\"Sequence {i+1}:\")\n",
    "    print(f\"  Input tokens: {input_token_sequences[i]}\")\n",
    "    print(f\"  Numerical data: {numerical_data_sequences[i]}\")\n",
    "    print(f\"  Output tokens: {output_token_sequences[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc74e48d",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "We need to encode our token sequences and combine them with numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode input tokens\n",
    "input_encoder = LabelEncoder()\n",
    "input_encoder.fit(input_tokens)\n",
    "\n",
    "# Encode output tokens (these are our hidden states)\n",
    "output_encoder = LabelEncoder()\n",
    "output_encoder.fit(output_tokens)\n",
    "\n",
    "# Prepare features by combining encoded input tokens and numerical data\n",
    "X_combined = []\n",
    "y = []\n",
    "\n",
    "for i in range(n_sequences):\n",
    "    # Encode input tokens for this sequence\n",
    "    encoded_input = input_encoder.transform(input_token_sequences[i])\n",
    "    \n",
    "    # Combine encoded input with numerical data\n",
    "    combined_features = np.column_stack((\n",
    "        encoded_input,  # Input token (encoded)\n",
    "        numerical_data_sequences[i]  # Numerical value\n",
    "    ))\n",
    "    \n",
    "    X_combined.append(combined_features)\n",
    "    \n",
    "    # Encode output tokens for this sequence\n",
    "    y.append(output_encoder.transform(output_token_sequences[i]))\n",
    "\n",
    "# Reshape for HMM input - concatenate all sequences\n",
    "X_train = np.vstack(X_combined)\n",
    "\n",
    "# Create sequence lengths array for the HMM\n",
    "lengths = [len(seq) for seq in X_combined]\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"Sequence lengths: {lengths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbdc089",
   "metadata": {},
   "source": [
    "## 3. Training the HMM\n",
    "\n",
    "We'll train a Gaussian HMM using the combined features (encoded input tokens + numerical data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5415da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the HMM\n",
    "n_states = len(output_tokens)  # Number of hidden states = number of output tokens\n",
    "model = hmm.GaussianHMM(\n",
    "    n_components=n_states,  # Number of hidden states\n",
    "    covariance_type=\"full\",  # Full covariance matrix for each state\n",
    "    n_iter=100,  # Max iterations for training\n",
    "    verbose=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, lengths)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(f\"Converged: {model.monitor_.converged}\")\n",
    "print(f\"Log-likelihood: {model.score(X_train, lengths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a167c3",
   "metadata": {},
   "source": [
    "## 4. Evaluating the Model\n",
    "\n",
    "Let's create a test set and see how well our model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a788789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a small test set\n",
    "n_test = 10\n",
    "\n",
    "# Create test sequences using the same logic as training set\n",
    "test_input_token_sequences = []\n",
    "for _ in range(n_test):\n",
    "    sequence = np.random.choice(input_tokens, size=sequence_length)\n",
    "    test_input_token_sequences.append(sequence)\n",
    "\n",
    "test_numerical_data_sequences = []\n",
    "for seq in test_input_token_sequences:\n",
    "    numerical_seq = []\n",
    "    for token in seq:\n",
    "        if token == 'A':\n",
    "            numerical_seq.append(np.random.normal(0.5, 0.1))\n",
    "        elif token == 'B':\n",
    "            numerical_seq.append(np.random.normal(1.2, 0.15))\n",
    "        elif token == 'C':\n",
    "            numerical_seq.append(np.random.normal(0.8, 0.12))\n",
    "        else:  # 'D'\n",
    "            numerical_seq.append(np.random.normal(1.5, 0.2))\n",
    "    test_numerical_data_sequences.append(np.array(numerical_seq))\n",
    "\n",
    "# Ground truth for test set\n",
    "test_output_token_sequences = []\n",
    "for i in range(n_test):\n",
    "    output_seq = []\n",
    "    for j in range(sequence_length):\n",
    "        input_token = test_input_token_sequences[i][j]\n",
    "        num_val = test_numerical_data_sequences[i][j]\n",
    "        \n",
    "        if input_token == 'A' and num_val < 0.5:\n",
    "            output_seq.append('X')\n",
    "        elif input_token == 'A' and num_val >= 0.5:\n",
    "            output_seq.append('Y')\n",
    "        elif input_token == 'B' and num_val < 1.2:\n",
    "            output_seq.append('X')\n",
    "        elif input_token == 'B' and num_val >= 1.2:\n",
    "            output_seq.append('Z')\n",
    "        elif input_token == 'C':\n",
    "            output_seq.append('Y')\n",
    "        else:  # 'D'\n",
    "            output_seq.append('Z')\n",
    "    \n",
    "    test_output_token_sequences.append(np.array(output_seq))\n",
    "\n",
    "# Prepare test data in the same way as training data\n",
    "X_test_combined = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(n_test):\n",
    "    # Encode input tokens for this sequence\n",
    "    encoded_input = input_encoder.transform(test_input_token_sequences[i])\n",
    "    \n",
    "    # Combine encoded input with numerical data\n",
    "    combined_features = np.column_stack((\n",
    "        encoded_input,\n",
    "        test_numerical_data_sequences[i]\n",
    "    ))\n",
    "    \n",
    "    X_test_combined.append(combined_features)\n",
    "    y_test.append(output_encoder.transform(test_output_token_sequences[i]))\n",
    "\n",
    "# Predict hidden states for each test sequence\n",
    "predicted_states = []\n",
    "for test_seq in X_test_combined:\n",
    "    # Predict hidden states\n",
    "    states = model.predict(test_seq)\n",
    "    predicted_states.append(states)\n",
    "\n",
    "# Convert predicted states back to output tokens\n",
    "predicted_output_sequences = []\n",
    "for states in predicted_states:\n",
    "    predicted_tokens = output_encoder.inverse_transform(states)\n",
    "    predicted_output_sequences.append(predicted_tokens)\n",
    "\n",
    "# Compare predictions to ground truth\n",
    "print(\"\\nTest Results:\")\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for i in range(n_test):\n",
    "    print(f\"\\nTest Sequence {i+1}:\")\n",
    "    print(f\"  Input tokens: {test_input_token_sequences[i]}\")\n",
    "    print(f\"  Numerical data: {test_numerical_data_sequences[i]}\")\n",
    "    print(f\"  True output: {test_output_token_sequences[i]}\")\n",
    "    print(f\"  Predicted output: {predicted_output_sequences[i]}\")\n",
    "    \n",
    "    # Count correct predictions\n",
    "    for j in range(len(test_output_token_sequences[i])):\n",
    "        total_predictions += 1\n",
    "        if test_output_token_sequences[i][j] == predicted_output_sequences[i][j]:\n",
    "            correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"\\nAccuracy: {accuracy:.2f} ({correct_predictions}/{total_predictions})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c26a0",
   "metadata": {},
   "source": [
    "## 5. Visualizing the HMM\n",
    "\n",
    "Let's visualize the transition and emission probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2213b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition matrix visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(model.transmat_, aspect='auto', cmap='YlGnBu')\n",
    "plt.colorbar()\n",
    "plt.title('Transition Probability Matrix')\n",
    "plt.xlabel('To state')\n",
    "plt.ylabel('From state')\n",
    "plt.xticks(np.arange(n_states), output_tokens)\n",
    "plt.yticks(np.arange(n_states), output_tokens)\n",
    "\n",
    "for i in range(n_states):\n",
    "    for j in range(n_states):\n",
    "        plt.text(j, i, f'{model.transmat_[i, j]:.2f}', \n",
    "                 ha='center', va='center', color='black')\n",
    "plt.show()\n",
    "\n",
    "# Means of emission distributions\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n_states):\n",
    "    plt.plot(model.means_[i], label=f'State {output_tokens[i]}')\n",
    "plt.title('Mean of Emission Distributions for Each State')\n",
    "plt.xlabel('Feature Index (0: Input Token, 1: Numerical Value)')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61dc4c0",
   "metadata": {},
   "source": [
    "## 6. Using the Model with New Data\n",
    "\n",
    "Now let's demonstrate how to use our trained HMM with new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e11c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new example sequence\n",
    "new_input_tokens = np.array(['A', 'B', 'C', 'D'])\n",
    "new_numerical_data = np.array([0.45, 1.3, 0.75, 1.6])\n",
    "\n",
    "# Prepare the new data\n",
    "encoded_new_input = input_encoder.transform(new_input_tokens)\n",
    "new_features = np.column_stack((encoded_new_input, new_numerical_data))\n",
    "\n",
    "# Predict the hidden states\n",
    "predicted_states = model.predict(new_features)\n",
    "predicted_output = output_encoder.inverse_transform(predicted_states)\n",
    "\n",
    "print(\"New sequence prediction:\")\n",
    "print(f\"  Input tokens: {new_input_tokens}\")\n",
    "print(f\"  Numerical data: {new_numerical_data}\")\n",
    "print(f\"  Predicted output: {predicted_output}\")\n",
    "\n",
    "# We can also get the probability of the predicted sequence\n",
    "log_prob = model.score(new_features)\n",
    "print(f\"  Log probability of the sequence: {log_prob:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bca78",
   "metadata": {},
   "source": [
    "## 7. Alternative Approach: Custom HMM Implementation\n",
    "\n",
    "If you need more flexibility, you can implement a custom HMM that directly models the relationship between tokens and numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a7d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a custom approach using pomegranate library\n",
    "# pip install pomegranate  # Uncomment and run this line if pomegranate is not installed\n",
    "\n",
    "from pomegranate import HiddenMarkovModel, DiscreteDistribution, NormalDistribution, IndependentComponentsDistribution\n",
    "import json\n",
    "from itertools import product\n",
    "\n",
    "def custom_hmm_approach():\n",
    "    # This is a skeleton implementation - would need to be completed\n",
    "    print(\"Custom HMM approach using pomegranate:\")\n",
    "    print(\"This would allow more complex emission distributions that model joint probabilities\")\n",
    "    print(\"of tokens and numerical values.\")\n",
    "    print(\"\\nExample implementation would include:\")\n",
    "    print(\"1. Create states with joint distributions for (token, numerical_value)\")\n",
    "    print(\"2. Define transitions between states\")\n",
    "    print(\"3. Train the model on sequences of (token, numerical_value) pairs\")\n",
    "    print(\"4. Predict output tokens for new sequences\")\n",
    "    \n",
    "    # Note: Full implementation would be more complex\n",
    "\n",
    "# Uncomment to run the custom approach example\n",
    "# custom_hmm_approach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e86a83",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "We've demonstrated how to:\n",
    "\n",
    "1. Prepare token sequences and numerical data for HMM training\n",
    "2. Train an HMM that can predict output tokens based on input tokens and numerical data\n",
    "3. Evaluate the model's performance\n",
    "4. Use the model to make predictions on new data\n",
    "\n",
    "The key insights are:\n",
    "- We can combine categorical (token) and numerical data into a single feature vector\n",
    "- The HMM can learn patterns in this combined feature space\n",
    "- The output tokens are represented as hidden states\n",
    "- You can extend this approach to more complex scenarios with longer sequences and more features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
